{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2270f5840caf2a7afa60683de5be0d494783ea94"
   },
   "source": [
    "**Youtube Video Statistics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "731e0a8e7a0c90ae8d14d24108fd544fe97a8b2e"
   },
   "source": [
    "In this Jupyter Notebook, I focussed on various key predictors like Comments, Dislikes, Views, and Likes. This notebook will guide you through the various methods like data wrangling, plotting, and analysing. In the lower part, I focussed on the Natural Language Processing. I predicted sentiments based on Tags, Description, and Title. I also formed WordCloud based on the frequency of the words.  \n",
    "\n",
    "**Key - NLP, NLTK, TextBlob, Sentiments, WordCloud**\n",
    "\n",
    "Note: Please do comment,  if the below scripts can be done in more suitable way. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f189981a-458e-4399-813e-dbfcc6afc272",
    "_uuid": "2c7b1daa6d77b9d150988f9d841838973a1a2b77",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e7705b81-97a2-4215-8523-d2a849ca80be",
    "_uuid": "de4c00fe8de04892aaa2b6bbe6aac146f98847c3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_usa=pd.read_csv(\"../input/USvideos.csv\")\n",
    "df_ca=pd.read_csv(\"../input/CAvideos.csv\")\n",
    "df_de=pd.read_csv(\"../input/DEvideos.csv\")\n",
    "df_fr=pd.read_csv(\"../input/FRvideos.csv\")\n",
    "df_gb=pd.read_csv(\"../input/GBvideos.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5f610a15-00a3-4553-a086-7bc60332176a",
    "_uuid": "0257e01471a48459fc158e568462b302d732358d"
   },
   "source": [
    "**In the dataset, the Trending Date and Published Time are not in the Unix date-time format. Let's fix this first. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9d092c43-13dc-48f2-86a2-f5d671684614",
    "_uuid": "3bccd84c2921bba19eac57cbe08bcb0b840a9171",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_usa['trending_date'] = pd.to_datetime(df_usa['trending_date'], format='%y.%d.%m')\n",
    "df_usa['publish_time'] = pd.to_datetime(df_usa['publish_time'], format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "# separates date and time into two columns from 'publish_time' column\n",
    "\n",
    "df_usa.insert(4, 'publish_date', df_usa['publish_time'].dt.date)\n",
    "df_usa['publish_time'] = df_usa['publish_time'].dt.time\n",
    "df_usa['publish_date']=pd.to_datetime(df_usa['publish_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f14c439b-924b-4754-a555-07eadc308093",
    "_uuid": "a3f2ef75394dadd868d8416775196f968493100e"
   },
   "source": [
    "**![](http://)To see the correlation between the likes, dislikes, comments, and views lets plot a correlation matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5a19b92f-178e-43b0-8ade-8f31d50425c3",
    "_uuid": "2cf284e7c98a1a867bf0b70be6c4c2f388cd3e72"
   },
   "outputs": [],
   "source": [
    "columns_show=['views', 'likes', 'dislikes', 'comment_count']\n",
    "f, ax = plt.subplots(figsize=(8, 8))\n",
    "corr = df_usa[columns_show].corr()\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax,annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4e43087f-b074-4df4-9846-58ae7890ff8c",
    "_uuid": "07b444f44d6d72b1f1e0d177ccc7fb1100437dbe"
   },
   "source": [
    "In the above matrix, for USA dataset, the columns with :-\n",
    " 1. High Correlation - Views and Likes,, Comment_count and Dislikes\n",
    " 2. Medium Correlation -  Views and Dislikes, Views and Comment_Count, Likes and Comment_Count\n",
    " 3. Low Correlation - Likes and Dislike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5d99a973-cf7e-4ea0-8021-f60b3a033509",
    "_uuid": "cd52ea1279bcffe7cbc1ed4d3796f0812035f962"
   },
   "source": [
    "**Since, a video could be in trending for several days. There might be multiple rows of a particular video. \n",
    "In order to calculate the total Views, Comments, Likes, Dislikes of a video,  we need to groupby with video_id. \n",
    "The below script will give you the total no. of views/comments/likes, and dislikes of a video.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d2851ded-36eb-4651-9cab-09625d3ab7a0",
    "_uuid": "d26bf4a3aa0b008f98bb5db782d2dd9f3d0a2540",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usa_video_views=df_usa.groupby(['video_id'])['views'].agg('sum')\n",
    "usa_video_likes=df_usa.groupby(['video_id'])['likes'].agg('sum')\n",
    "usa_video_dislikes=df_usa.groupby(['video_id'])['dislikes'].agg('sum')\n",
    "usa_video_comment_count=df_usa.groupby(['video_id'])['comment_count'].agg('sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2e94c012-6557-4bf3-bf0b-19f1678cf9c7",
    "_uuid": "6017420c479d224d313044596ea8354b27cd4ae7"
   },
   "source": [
    "**To get the numbers of videos on which the 'Comments Disabled/ Rating Disabled/Video Error'. We need to remove the duplicates to get the correct numbers otherwise there will be redundancy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dd101701-dcc5-4696-86b4-5e2d956da13c",
    "_uuid": "def6e99f82f4b2199b43aad5f0583a02e3adf8b5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_usa_single_day_trend=df_usa.drop_duplicates(subset='video_id', keep=False, inplace=False)\n",
    "df_usa_multiple_day_trend= df_usa.drop_duplicates(subset='video_id',keep='first',inplace=False)\n",
    "\n",
    "frames = [df_usa_single_day_trend, df_usa_multiple_day_trend]\n",
    "df_usa_without_duplicates=pd.concat(frames)\n",
    "\n",
    "df_usa_comment_disabled=df_usa_without_duplicates[df_usa_without_duplicates['comments_disabled']==True].describe()\n",
    "df_usa_rating_disabled=df_usa_without_duplicates[df_usa_without_duplicates['ratings_disabled']==True].describe()\n",
    "df_usa_video_error=df_usa_without_duplicates[df_usa_without_duplicates['video_error_or_removed']==True].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "83caa326-58d3-4c47-b7b0-0c407aa78f1c",
    "_uuid": "c59ba502dc63eb7d7fecdf051687f5c00ddb5558"
   },
   "source": [
    "**How many videos were trended only for a single day?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dae0a268-7cd2-4c5f-ad1b-5ee6bf786160",
    "_uuid": "82762303df8f26dece1f0de7f009b529f1e006b8"
   },
   "outputs": [],
   "source": [
    "df_usa_single_day_trend.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "daef722ff528729c45d1ced7abf473113b88dd60"
   },
   "source": [
    "Around 544 Videos were trended only for a single day in USA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "12f23fb962510bc71a5d5e4d76bf1347af3b2c1a"
   },
   "source": [
    "**Videos that were trended for  more than 1 day**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ac63fdb6078b283fc9d5ac1b60d6617d34467769"
   },
   "outputs": [],
   "source": [
    "df_usa_multiple_day_trend.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0b864cae938e6261380e1666108827dac0fc2205"
   },
   "source": [
    "Around 4079 videos were trended for more than one day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0493f7c1-ea0f-460d-8828-b80ccd1ddc00",
    "_uuid": "ae0be47b437bef71ae307ce7611bb4dcd1df293d"
   },
   "source": [
    "**Which video trended on maximum days and what is the title, likes, dislikes, comments, and views. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1d99efbf-29e9-404e-89d5-12999f57a0ed",
    "_uuid": "e8cb62dc3091729e52e311d8cd7eff61a254b6f7"
   },
   "outputs": [],
   "source": [
    "df_usa_which_video_trended_maximum_days=df_usa.groupby(by=['video_id'],as_index=False).count().sort_values(by='title',ascending=False).head()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.barplot(x=df_usa_which_video_trended_maximum_days['video_id'],y=df_usa_which_video_trended_maximum_days['trending_date'], data=df_usa_which_video_trended_maximum_days)\n",
    "plt.xlabel(\"Video Id\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 5 Videos that trended maximum days in USA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a019894fc82b57d3b24da3a76cb89d1e6bd6d08f"
   },
   "source": [
    "**Video which were trended for maximum days**\n",
    "\n",
    "The maximum no. of days a video trended is 14 i.e. for 'sXP6vliZIHI' video id. Now, the below script gives its likes,dislikes, views, and comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4f1be8a8-e070-434e-9e10-2a2edc5b4004",
    "_uuid": "8f6210508611ea5fc256550670e40cd39ddffb6e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_usa_maximum_views=usa_video_views['sXP6vliZIHI']\n",
    "df_usa_maximum_likes=usa_video_likes['sXP6vliZIHI']\n",
    "df_usa_maximum_dislikes=usa_video_dislikes['sXP6vliZIHI']\n",
    "df_usa_maximum_comment=usa_video_comment_count['sXP6vliZIHI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0eb927b4-ee3d-4f8e-91e7-8165de46e930",
    "_uuid": "7b20772ae08f83b519dca04886adcd3307b8e1c0"
   },
   "source": [
    "** Which video took maximum no of days to be a Trending Video-**\n",
    "\n",
    "Now, the below script will calculate the no of days taken by a video to be a Trending Video. The graph will show the top 5 videos that took maximum no. of days to be a trending video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4f187aaf-9d7a-494b-97b6-737b830fbb96",
    "_uuid": "c0187b9981ec8a9798b22d2ebfd40280e1abb1c1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_usa_multiple_day_trend['Days_taken_to_be_trending_video'] =df_usa_multiple_day_trend['trending_date'] - df_usa_multiple_day_trend['publish_date']\n",
    "df_usa_multiple_day_trend['Days_taken_to_be_trending_video']= df_usa_multiple_day_trend['Days_taken_to_be_trending_video'] / np.timedelta64(1, 'D')\n",
    "usa_no_of_days_take_trend=df_usa_multiple_day_trend.sort_values(by='Days_taken_to_be_trending_video',ascending=False).head(5)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.barplot(x=usa_no_of_days_take_trend['title'],y=usa_no_of_days_take_trend['Days_taken_to_be_trending_video'], data=usa_no_of_days_take_trend)\n",
    "plt.xlabel(\"Video Title\")\n",
    "plt.ylabel(\"No. of Days\")\n",
    "plt.title(\"Maximum no of days taken by 5 videos to be popular in USA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79162ec9-da06-41e7-814c-bc72bd634f29",
    "_uuid": "eefda897a40f4e14fcba94dfad516927041af329"
   },
   "source": [
    "Strange !! I never imagined this figure. Some videos taken more than 10 years to be in Trending. The video_id MJO3FmmFuh4 taken maximum 4215 days to be called a Trending.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7d7fef71-7f9f-413b-94a3-57c1a7772eb3",
    "_uuid": "02e770b80bc24a052f27b7c060ef98e0fee67bf5"
   },
   "source": [
    "**Top 5 Trending Channel in USA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "802f4d7d-debb-4b3a-8a51-ced051d25d8b",
    "_uuid": "74ca3fb598cc1c281cdccd5b5411cadd58177c91"
   },
   "outputs": [],
   "source": [
    "usa_trending_channel=df_usa_without_duplicates.groupby(by=['channel_title'],as_index=False).count().sort_values(by='title',ascending=False).head()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.barplot(x=usa_trending_channel['channel_title'],y=usa_trending_channel['video_id'], data=usa_trending_channel)\n",
    "plt.xlabel(\"Channel Title\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 5 Trending Channel in USA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c00b715f-de82-4db5-8bbf-e278cfc539a6",
    "_uuid": "8c911d9eed47ccc6ec0221da2664a5849c71043d"
   },
   "source": [
    "**Top 5 USA_Category_IDs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ce1b22c1-0e56-4bc7-aa77-23c97df6e8cd",
    "_uuid": "611d6f48d9236fe2ccfcc696885cdfd83d4dc0a2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "usa_category_id=df_usa_without_duplicates.groupby(by=['category_id'],as_index=False).count().sort_values(by='title',ascending=False).head(5)\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "sns.kdeplot(usa_category_id['category_id']);\n",
    "plt.xlabel(\"Category IDs\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Top 5 Category IDs for USA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "897dd8e0-f3da-4326-9c10-f72c3e5b8ce5",
    "_uuid": "ffee80b7142323cc2c3eacf088ff2b4a943b3eba"
   },
   "source": [
    "This graph shows that the maximum category_id is 24 and the Category_Ids are majorly between 22-27."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "01a0a3e5-918f-4aa8-ba2e-e1576ab178cf",
    "_uuid": "72dba6c5ea0f9ae6c5f3a61803b3fbb73503a21a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "def wc(data,bgcolor,title):\n",
    "    plt.figure(figsize = (100,100))\n",
    "    wc = WordCloud(background_color = bgcolor, max_words = 1000,  max_font_size = 50)\n",
    "    wc.generate(' '.join(data))\n",
    "    plt.imshow(wc)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cdaa9328-dbd9-42b5-b67d-53492452da55",
    "_uuid": "524c267d0722ab81d861560401d276a7328611eb"
   },
   "source": [
    "**To Count the frequency of words in Title column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "26ff650a-fbb5-4f6c-963a-71115f6e82ad",
    "_uuid": "132132e074d3078042da1c83b19bccc1ae00df80"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "import re\n",
    "\n",
    "top_N = 100\n",
    "#convert list of list into text\n",
    "#a=''.join(str(r) for v in df_usa['title'] for r in v)\n",
    "\n",
    "a = df_usa['title'].str.lower().str.cat(sep=' ')\n",
    "\n",
    "# removes punctuation,numbers and returns list of words\n",
    "b = re.sub('[^A-Za-z]+', ' ', a)\n",
    "\n",
    "#remove all the stopwords from the text\n",
    "stop_words = list(get_stop_words('en'))         \n",
    "nltk_words = list(stopwords.words('english'))   \n",
    "stop_words.extend(nltk_words)\n",
    "\n",
    "word_tokens = word_tokenize(b)\n",
    "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "filtered_sentence = []\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "\n",
    "# Remove characters which have length less than 2  \n",
    "without_single_chr = [word for word in filtered_sentence if len(word) > 2]\n",
    "\n",
    "# Remove numbers\n",
    "cleaned_data_title = [word for word in without_single_chr if not word.isnumeric()]        \n",
    "\n",
    "# Calculate frequency distribution\n",
    "word_dist = nltk.FreqDist(cleaned_data_title)\n",
    "rslt = pd.DataFrame(word_dist.most_common(top_N),\n",
    "                    columns=['Word', 'Frequency'])\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.barplot(x=\"Word\",y=\"Frequency\", data=rslt.head(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "db52c498-19ae-4b29-9a11-65922babd9d5",
    "_uuid": "5175d1eaa3d75a4305785acf2630127e713a6860",
    "collapsed": true
   },
   "source": [
    "**WordCloud for Title Column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "afd32ec6-2be0-4375-97e6-27d0e9fb8684",
    "_uuid": "e7e99a53f1e653b4c62a2dbc830bf9ef88b6b451"
   },
   "outputs": [],
   "source": [
    "wc(cleaned_data_title,'black','Common Words' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2473cf5f-cd55-4fb4-8c06-39fad730c548",
    "_uuid": "c3261d33abbfd7c41ac433c3a6e51760ff211e37"
   },
   "source": [
    "**To Count the frequency of words in Tags column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "be00c04c-6c80-47f8-9edf-5d75dc724db4",
    "_uuid": "afca9f245dbad07892bb4a117769964cc67d2c43"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "import re\n",
    "\n",
    "top_N = 100\n",
    "#convert list of list into text\n",
    "#a=''.join(str(r) for v in df_usa['title'] for r in v)\n",
    "\n",
    "tags_lower = df_usa['tags'].str.lower().str.cat(sep=' ')\n",
    "\n",
    "# removes punctuation,numbers and returns list of words\n",
    "tags_remove_pun = re.sub('[^A-Za-z]+', ' ', tags_lower)\n",
    "\n",
    "#remove all the stopwords from the text\n",
    "stop_words = list(get_stop_words('en'))         \n",
    "nltk_words = list(stopwords.words('english'))   \n",
    "stop_words.extend(nltk_words)\n",
    "\n",
    "word_tokens_tags = word_tokenize(tags_remove_pun)\n",
    "filtered_sentence_tags = [w_tags for w_tags in word_tokens_tags if not w_tags in stop_words]\n",
    "filtered_sentence_tags = []\n",
    "for w_tags in word_tokens_tags:\n",
    "    if w_tags not in stop_words:\n",
    "        filtered_sentence_tags.append(w_tags)\n",
    "\n",
    "# Remove characters which have length less than 2  \n",
    "without_single_chr_tags = [word_tags for word_tags in filtered_sentence_tags if len(word_tags) > 2]\n",
    "\n",
    "# Remove numbers\n",
    "cleaned_data_tags = [word_tags for word_tags in without_single_chr_tags if not word_tags.isnumeric()]        \n",
    "\n",
    "# Calculate frequency distribution\n",
    "word_dist_tags = nltk.FreqDist(cleaned_data_tags)\n",
    "rslt_tags = pd.DataFrame(word_dist_tags.most_common(top_N),\n",
    "                    columns=['Word', 'Frequency'])\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.barplot(x=\"Word\",y=\"Frequency\", data=rslt_tags.head(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f27523b6-1e6f-4179-8897-78d8b9d0f299",
    "_uuid": "7731a7cb0f28bc12123ef70eab6566bba70bea74"
   },
   "source": [
    "**WordCloud for Tags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9cc38479-b863-47f0-83f4-2639e86795b2",
    "_uuid": "78cc8e9b2637042d15e963483be0e29d3dd8e6b6"
   },
   "outputs": [],
   "source": [
    "wc(cleaned_data_tags,'black','Common Words' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "04e56df6-e51c-4695-8477-9393fb2feaef",
    "_uuid": "58e6489fcb55fff4b9c3d04e65705954bf245843"
   },
   "source": [
    "**To Count the frequency of words in Description column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ee56f1b1-6c3e-4e0a-859e-cb4a4ee35f2f",
    "_uuid": "938b4a1caef9e13bef07f57e91fdbcaba0362ae1"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "import re\n",
    "\n",
    "top_N = 100\n",
    "#convert list of list into text\n",
    "#a=''.join(str(r) for v in df_usa['title'] for r in v)\n",
    "\n",
    "desc_lower = df_usa['description'].str.lower().str.cat(sep=' ')\n",
    "\n",
    "# removes punctuation,numbers and returns list of words\n",
    "desc_remove_pun = re.sub('[^A-Za-z]+', ' ', desc_lower)\n",
    "\n",
    "#remove all the stopwords from the text\n",
    "stop_words = list(get_stop_words('en'))         \n",
    "nltk_words = list(stopwords.words('english'))   \n",
    "stop_words.extend(nltk_words)\n",
    "\n",
    "word_tokens_desc = word_tokenize(desc_remove_pun)\n",
    "filtered_sentence_desc = [w_desc for w_desc in word_tokens_desc if not w_desc in stop_words]\n",
    "filtered_sentence_desc = []\n",
    "for w_desc in word_tokens_desc:\n",
    "    if w_desc not in stop_words:\n",
    "        filtered_sentence_desc.append(w_desc)\n",
    "\n",
    "# Remove characters which have length less than 2  \n",
    "without_single_chr_desc = [word_desc for word_desc in filtered_sentence_desc if len(word_desc) > 2]\n",
    "\n",
    "# Remove numbers\n",
    "cleaned_data_desc = [word_desc for word_desc in without_single_chr_desc if not word_desc.isnumeric()]        \n",
    "\n",
    "# Calculate frequency distribution\n",
    "word_dist_desc = nltk.FreqDist(cleaned_data_desc)\n",
    "rslt_desc = pd.DataFrame(word_dist_desc.most_common(top_N),\n",
    "                    columns=['Word', 'Frequency'])\n",
    "\n",
    "#print(rslt_desc)\n",
    "#plt.style.use('ggplot')\n",
    "#rslt.plot.bar(rot=0)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.barplot(x=\"Word\", y=\"Frequency\", data=rslt_desc.head(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "06369936-ac5d-4794-b12e-e40c9eca0097",
    "_uuid": "1f37cdd2fdb9768ce423f3a63009cd2ef077807b"
   },
   "source": [
    "**WordCloud for Description column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7ce7bcf5-d26a-4186-8d40-27d1f758231a",
    "_uuid": "4581877015f3e447c6ff288e11d27272ff69153f"
   },
   "outputs": [],
   "source": [
    "wc(cleaned_data_desc,'black','Frequent Words' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5bba1d78-14ea-400b-8c5e-5d786b99bd69",
    "_uuid": "7056afa4b9b007929ca70a7145bcd6084e2cbda4"
   },
   "source": [
    "**Categorize the Description column into Positive and Negative sentiments using TextBlob**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "13e86ad4-9de9-4620-8120-d47cbdbf94ab",
    "_uuid": "944b55d0cd12c1010bfc635d425e1cdefa068bbc"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "bloblist_desc = list()\n",
    "\n",
    "df_usa_descr_str=df_usa['description'].astype(str)\n",
    "for row in df_usa_descr_str:\n",
    "    blob = TextBlob(row)\n",
    "    bloblist_desc.append((row,blob.sentiment.polarity, blob.sentiment.subjectivity))\n",
    "    df_usa_polarity_desc = pd.DataFrame(bloblist_desc, columns = ['sentence','sentiment','polarity'])\n",
    " \n",
    "def f(df_usa_polarity_desc):\n",
    "    if df_usa_polarity_desc['sentiment'] > 0:\n",
    "        val = \"Positive\"\n",
    "    elif df_usa_polarity_desc['sentiment'] == 0:\n",
    "        val = \"Neutral\"\n",
    "    else:\n",
    "        val = \"Negative\"\n",
    "    return val\n",
    "\n",
    "df_usa_polarity_desc['Sentiment_Type'] = df_usa_polarity_desc.apply(f, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.countplot(x=\"Sentiment_Type\", data=df_usa_polarity_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bbffb9d6-ceaf-428b-a796-2e749d1f7235",
    "_uuid": "ab31910e607d101b03ebedcc3d1fb56268a2f1d8",
    "collapsed": true
   },
   "source": [
    "**Categorize the Tags column into Positive and Negative sentiments using TextBlob**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a4aa3cb5-05bb-4cda-a305-a9f49d9b8d30",
    "_uuid": "e6177adfd743f62ea9a2c2c53bff4de3f779c0c8"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "bloblist_tags = list()\n",
    "\n",
    "df_usa_tags_str=df_usa['tags']\n",
    "for row in df_usa_tags_str:\n",
    "    blob = TextBlob(row)\n",
    "    bloblist_tags.append((row,blob.sentiment.polarity, blob.sentiment.subjectivity))\n",
    "    df_usa_polarity_tags = pd.DataFrame(bloblist_tags, columns = ['sentence','sentiment','polarity'])\n",
    " \n",
    "def f_tags(df_usa_polarity_tags):\n",
    "    if df_usa_polarity_tags['sentiment'] > 0:\n",
    "        val = \"Positive\"\n",
    "    elif df_usa_polarity_tags['sentiment'] == 0:\n",
    "        val = \"Neutral\"\n",
    "    else:\n",
    "        val = \"Negative\"\n",
    "    return val\n",
    "\n",
    "df_usa_polarity_tags['Sentiment_Type'] = df_usa_polarity_tags.apply(f_tags, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.countplot(x=\"Sentiment_Type\", data=df_usa_polarity_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "11f90506-5545-419d-9151-7187e90fd452",
    "_uuid": "40497cb5061d3f58b17b7c91d937f9650f513a4d"
   },
   "source": [
    "**Categorize the Title column into Positive and Negative sentiments using TextBlob**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1a310aa6-2bd9-447b-8ea2-2b30f983fc9d",
    "_uuid": "5e3438246f0e55e91fab1d036261b88d98ca178a"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "bloblist_title = list()\n",
    "\n",
    "df_usa_title_str=df_usa['title']\n",
    "for row in df_usa_title_str:\n",
    "    blob = TextBlob(row)\n",
    "    bloblist_title.append((row,blob.sentiment.polarity, blob.sentiment.subjectivity))\n",
    "    df_usa_polarity_title = pd.DataFrame(bloblist_title, columns = ['sentence','sentiment','polarity'])\n",
    " \n",
    "def f_title(df_usa_polarity_title):\n",
    "    if df_usa_polarity_title['sentiment'] > 0:\n",
    "        val = \"Positive\"\n",
    "    elif df_usa_polarity_title['sentiment'] == 0:\n",
    "        val = \"Neutral\"\n",
    "    else:\n",
    "        val = \"Negative\"\n",
    "    return val\n",
    "\n",
    "df_usa_polarity_title['Sentiment_Type'] = df_usa_polarity_title.apply(f_title, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.countplot(x=\"Sentiment_Type\", data=df_usa_polarity_title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b53cc233-0ff2-40c4-88fd-7d226a60fd49",
    "_uuid": "1de0cd78eba583834c92150c5c17173fb17bfa2b",
    "collapsed": true
   },
   "source": [
    "**Thanks. Any suggestions are welcomed :)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
